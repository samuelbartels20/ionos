# OpenTelemetry Collector Configuration
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
  namespace: observability
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/component: collector
    app.kubernetes.io/version: "0.128.0"
    app.kubernetes.io/managed-by: opentelemetry-operator
spec:
  mode: deployment
  managementState: "managed"

  # Resource Management & Autoscaling
  resources:
    requests:
      cpu: 200m
      memory: 400Mi
    limits:
      cpu: 1
      memory: 2Gi

  # Auto-scaling Configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Multi-Protocol Telemetry Ports
  ports:
    # Health and metrics
    - name: health
      port: 13113
    - name: metrics
      port: 8888

    # OTLP receivers
    - name: otlp-grpc
      port: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      protocol: TCP

    # Jaeger receivers
    - name: jaeger-grpc
      port: 14250
      protocol: TCP
    - name: jaeger-thrift-http
      port: 14268
      protocol: TCP

    # Zipkin receiver
    - name: zipkin
      port: 9411
      protocol: TCP

    # Prometheus receiver
    - name: prometheus
      port: 9090
      protocol: TCP

  # Enterprise Security
  securityContext:
    runAsNonRoot: true
    runAsUser: 10001
    fsGroup: 10001
    seccompProfile:
      type: RuntimeDefault

  # Pod Security
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 10001
    fsGroup: 10001
    seccompProfile:
      type: RuntimeDefault

  # Environment Variables
  env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: HOST_IP
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: "service.name=opentelemetry-collector,service.namespace=$(POD_NAMESPACE),host.name=$(NODE_NAME)"

  # Comprehensive Telemetry Configuration
  config: |
    # === RECEIVERS === #
    receivers:
      # OTLP Multi-Protocol Receiver
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
            tls:
              enabled: false
          http:
            endpoint: 0.0.0.0:4318
            tls:
              enabled: false

      # Jaeger Multi-Protocol Receiver
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268

      # Zipkin Receiver
      zipkin:
        endpoint: 0.0.0.0:9411

      # Prometheus Scraping
      prometheus:
        config:
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          scrape_configs:
          - job_name: 'kubernetes-pods'
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: kubernetes_pod_name

      # Enhanced File Log Collection
      filelog:
        include: [ /var/log/pods/*/*/*.log ]
        exclude: []
        start_at: end
        include_file_path: true
        include_file_name: false
        operators:
          - type: router
            id: get-format
            routes:
              - output: parser-docker
                expr: 'body matches "^\\{"'
              - output: parser-cri
                expr: 'body matches "^[^ Z]+ "'
              - output: parser-plain
                expr: true
          - type: json_parser
            id: parser-docker
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          - type: regex_parser
            id: parser-cri
            regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: time
              layout: '%Y-%m-%dT%H:%M:%S.%L%z'
          - type: move
            id: parser-plain
            from: body
            to: log
            output: extract_metadata_from_filepath
          - type: regex_parser
            id: extract_metadata_from_filepath
            regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
            parse_from: attributes["log.file.path"]
          - type: move
            from: attributes["log.file.path"]
            to: attributes["file.path"]
          - type: add
            field: attributes["k8s.container.name"]
            value: EXPR(attributes["container_name"])
          - type: add
            field: attributes["k8s.namespace.name"]
            value: EXPR(attributes["namespace"])
          - type: add
            field: attributes["k8s.pod.name"]
            value: EXPR(attributes["pod_name"])
          - type: add
            field: attributes["k8s.container.restart_count"]
            value: EXPR(attributes["restart_count"])
          - type: remove
            field: attributes["container_name"]
          - type: remove
            field: attributes["namespace"]
          - type: remove
            field: attributes["pod_name"]
          - type: remove
            field: attributes["restart_count"]

    # === PROCESSORS === #
    processors:
      # Memory Limiter (Critical for Stability)
      memory_limiter:
        check_interval: 1s
        limit_percentage: 80
        spike_limit_percentage: 25

      # Enhanced Batching
      batch:
        send_batch_size: 10000
        timeout: 10s

      # Kubernetes Attributes Enhancement
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.container.name
            - k8s.node.name
            - k8s.pod.start_time
          annotations:
            - tag_name: container.image.tag
              key: container.image.tag
            - tag_name: deployment.environment
              key: environment
          labels:
            - tag_name: k8s.pod.label.component
              key: component
            - tag_name: k8s.pod.label.version
              key: version

      # Resource Enhancement
      resource:
        attributes:
          - key: deployment.environment
            value: production
            action: insert
          - key: service.version
            from_attribute: k8s.pod.label.version
            action: insert
          - key: service.instance.id
            from_attribute: k8s.pod.uid
            action: insert

      # Data Transformation
      transform:
        error_mode: ignore
        trace_statements:
          - context: resource
            statements:
              - set(attributes["service.namespace"], attributes["k8s.namespace.name"])
              - set(attributes["service.instance.id"], attributes["k8s.pod.uid"])
        metric_statements:
          - context: resource
            statements:
              - set(attributes["service.namespace"], attributes["k8s.namespace.name"])
              - set(attributes["service.instance.id"], attributes["k8s.pod.uid"])
        log_statements:
          - context: resource
            statements:
              - set(attributes["service.namespace"], attributes["k8s.namespace.name"])
              - set(attributes["service.instance.id"], attributes["k8s.pod.uid"])

      # PII/PHI Redaction
      filter:
        error_mode: ignore
        metrics:
          include:
            match_type: regexp
            metric_names:
              - .*
        logs:
          include:
            match_type: regexp
            record_attributes:
              - key: severity_text
                value: .*
          exclude:
            match_type: strict
            record_attributes:
              - key: http.target
                value: /health
              - key: http.target
                value: /ready
        traces:
          include:
            match_type: regexp
            services:
              - .*
          exclude:
            match_type: strict
            span_names:
              - /health
              - /ready

      # Advanced Filtering
      probabilistic_sampler:
        hash_seed: 42
        sampling_percentage: 10

    # === CONNECTORS === #
    connectors:
      # Span Metrics Generation
      spanmetrics:
        metrics_exporter: prometheus
        latency_histogram_buckets: [1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
        dimensions:
          - name: service.name
            default: unknown-service
          - name: operation
            default: unknown-operation
          - name: http.status_code

      # Service Graph Generation
      servicegraph:
        metrics_exporter: prometheus
        dimensions:
          - name: client
            default: unknown-client
          - name: server
            default: unknown-server
          - name: failed
            default: "false"

    # === EXPORTERS === #
    exporters:
      # OTLP to Alloy (Primary)
      otlp/alloy:
        endpoint: alloy:4317
        tls:
          insecure: true
        sending_queue:
          enabled: true
          queue_size: 5000
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s

      # Direct Loki Export (Backup)
      loki:
        endpoint: http://loki-gateway.observability.svc.cluster.local/loki/api/v1/push
        tenant_id: ""
        labels:
          attributes:
            container: k8s.container.name
            namespace: k8s.namespace.name
            node: k8s.node.name
            pod: k8s.pod.name
          resource:
            service.name: service.name
            service.namespace: service.namespace

      # Direct Mimir Export (Backup)
      prometheusremotewrite:
        endpoint: http://mimir-nginx.observability.svc.cluster.local/api/v1/push
        tls:
          insecure: true
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s

      # Debug Export (Development)
      debug:
        verbosity: detailed

    # === EXTENSIONS === #
    extensions:
      # Health Check Extension
      health_check:
        endpoint: 0.0.0.0:13133
        path: /health

      # Performance Profiling
      pprof:
        endpoint: 0.0.0.0:1777

      # zPages for Diagnostics
      zpages:
        endpoint: 0.0.0.0:55679

    # === SERVICE PIPELINE CONFIGURATION === #
    service:
      extensions: [health_check, pprof, zpages]

      pipelines:
        # Comprehensive Traces Pipeline
        traces:
          receivers: [otlp, jaeger, zipkin]
          processors: [memory_limiter, k8sattributes, batch, resource, transform, probabilistic_sampler]
          exporters: [otlp/alloy, debug]

        # Enhanced Metrics Pipeline
        metrics:
          receivers: [otlp, prometheus]
          processors: [memory_limiter, k8sattributes, batch, resource, transform, filter]
          exporters: [otlp/alloy, prometheusremotewrite, debug]

        # Production Logs Pipeline
        logs:
          receivers: [otlp, filelog]
          processors: [memory_limiter, k8sattributes, batch, resource, transform, filter]
          exporters: [otlp/alloy, loki, debug]

      # Telemetry Configuration
      telemetry:
        logs:
          level: info
          development: false
        metrics:
          level: detailed
          address: 0.0.0.0:8888

  # Pod Affinity & Anti-Affinity
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - opentelemetry-collector
          topologyKey: kubernetes.io/hostname

  # Tolerations for Special Nodes
  tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"
  - key: "node-role.kubernetes.io/master"
    operator: "Exists"
    effect: "NoSchedule"

  # Volume Mounts for Log Collection
  volumeMounts:
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true

  # Volumes
  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods
